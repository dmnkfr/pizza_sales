---
title: "Pizza Sales - A Case Study"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

## Libraries
source("requirements.R")
```

### Preprocessing

Please refer to `./scripts/clean_data.R` for loading and tidying the raw data. After loading the relevant part of the raw excel file, the following steps were done:

1.  Clean variable names
2.  Clean `year` and `week` variables
3.  Filter data for week 53
4.  Create a clean `date` variable from `year` and `week`
5.  Combine all calendar variables to a single `holiday` variable
6.  Sum all own campaign variables to single `own_campaigns` variable, since they do not overlapo in time
7.  Sum all competitor campaign variables to single `competitor_campaigns_sum` variable
8.  Average all competitor campaign variables to single `competitor_campaigns_mean` variable
9.  Sum all own and competitor campaign variables to single `campaigns_sum` variable
10. Select relevant variables and write data to `./data/processed/data_clean.feather`

```{r, echo=False}
source("./scripts/clean_data.R")
```

Load and preview tidy data frame.

```{r, echo=False}
data <- feather::read_feather("./data/processed/data_clean.feather") %>%
  mutate(
    year = as.integer(year),
    week = as.integer(week)
  )

head(data) %>% tibble()
```

A first glimpse at the central tendency our variables to get a first idea of our data set.

```{r, echo=False}
data %>%
  select(-c(date, holiday, temperature, sun, precipitation, competitor_1:competitor_7)) %>%
  psych::describe(skew = FALSE)
```

We can see that we have **data from five years 2017-2021.** Our **own campaigns reach on average more people than our competitors' campaigns** even though our reach varies way more. However, all competitors combined have of course a way greater reach than our campaigns.

### Task 1: Plot variables

Let's first have a look at our main **KPI pizza sales** from 2017 through 2021:

```{r sales_plot, echo=FALSE}
data %>%
  ggplot(aes(x = date, y = pizza)) +
  ## Add pizza sales
  geom_line(aes(x = date, y = pizza),
    color = "#E0E0E0"
  ) +
  ylim(c(0, max(data$pizza))) +
  ## 4-week moving avg
  stat_smooth(
    method = "loess",
    span = 4 / 52,
    color = "#2EC2C7"
  ) +
  ## Add trendline
  geom_smooth(method = "lm", 
              se = FALSE, 
              color = "#A92F62",
              linetype="dashed") +
  ## Style  
  ggtitle("Pizza Sales 2017-2021") +
  ylab("Pizza sales in pizzas") +
  theme_ipsum(
    plot_title_face = "plain",
    plot_title_size = 14,
    grid = "Y"
  ) +
  scale_x_date(expand = c(0,0))+
  xlab("Year") +
  theme_ipsum(grid = TRUE)
  
```

We get some first interesting insight:

1.  There is **unseasonal variation**
2.  Overall, sales increase.

First, let's look at the same data aggregated by year.

```{r sales-agg, echo=FALSE}
data %>%
  ggplot( aes(x=as.factor(year), y=pizza, fill=as.factor(year))) +
    geom_violin() +
    geom_boxplot(width=0.1, color="grey", alpha=0.2) +
    scale_fill_viridis(discrete = TRUE, option="G") +
    theme_ipsum() +
    theme(
      legend.position="none",
    ) +
    ggtitle("Pizza Sales by Year") +
    xlab("Year") +
    ylab("Pizza sales in pizzas")
```

We see that the trend line in the first plot missed that 2021 actually saw a slight decrease in sales, which we can also see in below table that gives us **total sales per year.**

```{r, echo=FALSE}
data %>% 
  group_by(year) %>% 
  summarise(total_pizza = round(sum(pizza),2)) %>% tibble()
```

Let's look at the same data but with some other variables that could drive our sales, beginning with **sales offer**, which gives us the deviation from the standard price of our frozen pizza in percent.

```{r sales-offer, echo=FALSE}
sales_plot <- data %>%
  ggplot(aes(x = date, y = pizza)) +
  ## Add pizza sales
  geom_line(aes(x = date, y = pizza),
    color = "#E0E0E0"
  ) +
  ylim(c(min(data$pizza), max(data$pizza))) +
  ## 4-week moving avg
  stat_smooth(
    method = "loess",
    span = 4 / 52,
    color = "#2EC2C7"
  ) +
  ## Style
  ylab("Pizza sales") +
  theme_ipsum(
    grid = TRUE
  ) +
  theme(
    axis.line.x = element_blank(),
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    plot.margin = unit(c(1, 1, 0, 1), "cm")
  )

offer_plot <- data %>%
  ggplot(aes(x = date, y = price_offer)) +
  geom_line(color = "#E0E0E0") +
  ## 4-week moving avg
  stat_smooth(
    method = "loess",
    span = 4 / 52,
    color = "#9474CA",
    se = FALSE
  ) +
  ## Style
  ylab("Price offer in %") +
  theme_ipsum(
    grid = TRUE
  ) +
  xlab("Year")+
  theme(plot.margin = unit(c(0, 1, 1, 1), "cm"))

sales_plot <- sales_plot +
  ggtitle("Pizza Sales and Price Offer 2017-2021")

gridExtra::grid.arrange(sales_plot,
  offer_plot,
  ncol = 1
)
```

Here we can already see a clear correlation between pizza price and sales. Let's look at the sales data in combination with our own **campaign data.**

```{r sales-owncampaign, echo=FALSE}
own_campaign_plot <- data %>%
  ggplot(aes(x = date, y = own_campaigns)) +
  geom_line(color = "#E0E0E0") +
  ## 2-week moving avg
  stat_smooth(
    method = "loess",
    span = 2 / 52,
    color = "#9474CA",
    se = FALSE
  ) +
  ## Style
  ylab("Reach in total people reached") +
  theme_ipsum(
    grid = TRUE
  ) +
  xlab("Year")+
  theme(plot.margin = unit(c(0, 1, 1, 1), "cm"))

sales_plot <- sales_plot +
  ggtitle("Pizza Sales and Own Campaign Reach 2017-2021")

gridExtra::grid.arrange(sales_plot,
  own_campaign_plot,
  ncol = 1
)
```

We can see that some but not all campaigns drive our sales. Let's have a look at our **competitors' campaigns**. Specifically, we will look at the **total reach of all competitors combined.**

```{r sales-compcampaign, echo=FALSE}
comp_campaign_plot <- data %>%
  ggplot(aes(x = date, y = competitor_campaigns_sum)) +
  geom_line(color = "#E0E0E0") +
  ## 2-week moving avg
  stat_smooth(
    method = "loess",
    span = 2 / 52,
    color = "#9474CA",
    se = FALSE
  ) +
  ## Style
  ylab("Reach in total people reached") +
  theme_ipsum(
    grid = TRUE
  ) +
  xlab("Year")+
  theme(plot.margin = unit(c(0, 1, 1, 1), "cm"))

sales_plot <- sales_plot +
  ggtitle("Pizza Sales and Competitors' Campaign Reach 2017-2021")

gridExtra::grid.arrange(sales_plot,
  comp_campaign_plot,
  ncol = 1
)
```

Let's look at a **correlation matrix of pizza sales, price offer, own campaign and competitor campaign reach.**

```{r plot-campaign-offer-sales, echo=False}
cor_cols <- c(
  "pizza",
  "price_offer",
  "own_campaigns",
  "competitor_campaigns_sum"
)

ggpairs(data, columns = cor_cols) +
  theme_ipsum()
```

These all seem to be great candidates for sales predictors.

Finally, let's also have a look at the weather variables, i.e., **temperature and precipitation** over the five years, aggregated by month.

```{r plot-weather, echo=False}
data %>% 
  mutate(month = month(date)) %>%
  group_by(month, year) %>%
  summarize(temperature = mean(temperature),
            precipitation = mean(precipitation)) %>% 
  ggplot(aes(x= month)) +
    geom_bar(aes(y= precipitation, fill = "precipitation"), stat="identity")  +
    geom_line(aes(y = temperature, color = "temperature")) +
    geom_point(aes(y = temperature)) +
    scale_x_discrete(limits = month.name) +
    scale_y_continuous(
      expression("Average Monthly Temperature " ( degree*C)), 
      sec.axis = sec_axis(~ . * 4, name = "Monthly Precipitation (mm)")
    ) +
    scale_colour_manual("", values = c("temperature" = "black")) +
    scale_fill_manual("", values = "#FFA17D") +
    theme_ipsum()+
    theme(axis.text.x = element_text(size=7, angle=90, hjust=1),
          legend.position="none") +
    facet_wrap(~year,
               ncol=5)

```

**2021 was very rainy,** which might explain the lower pizza sales to some degree. However, it was also the year (almost) post pandemic. Let's see if a correlation plot could corroborate this assumption.

```{r plot-weather-sales, echo=False}
cor_cols <- c(
  "pizza",
  "temperature",
  "sun",
  "precipitation"
)

ggpairs(data, columns = cor_cols) +
  theme_ipsum()
```

Not really. However, **temperature correlates both with hours of sun per day and precipitation in millimeters**, so we might use only temperature as a predictor later on.

For now, we can summarize that **sales offer, our own as well as our competitors' campaign reach might be valuable sales predictors**.

### Task 2: Summary table

A table with **min, max, total per variable**.

```{r summary-table, echo=False}
data %>% 
  select(pizza,
         price_offer,
         holiday,
         temperature,
         precipitation,
         sun,
         own_campaigns,
         competitor_campaigns_sum) %>% 
  gather(variable, value) %>%
  group_by(variable) %>%
  summarize(min = min(value), 
            max = max(value), 
            total = sum(value)) %>%
  tibble()

```

### Task 3: Model pizza sales

For this task, we split data into a **training and test set.** Let's assume we have data only for 2017-2020 and use it to predict the 2021 data.

```{r linear-reg1, echo=False}
training <- data %>% 
  filter(year!=2021)

predictors <- training[, c(
  "price_offer",
  "own_campaigns",
  "competitor_1",
  "competitor_2",
  "competitor_3",
  "competitor_4",
  "competitor_5",
  "competitor_6",  
  "competitor_7",
  "temperature",
  "holiday"
)]

response <- training$pizza

# Define the model and training control
linear_model2 <- train(predictors, response,
                      method = "lm",
                      trControl = trainControl(method = "cv", number = 5),
                      preProcess = c("scale"),
                      na.action = na.pass)

# Print the model summary
print(summary(linear_model2))
```

Competitor 1 seems to be correlated with our own campaigns or offers. Other than that, we see that the residuals are close to normally distributed, confirming a basic model assumption.

```{r plot-comp-own, echo=False}
cor_cols <- c(
  "price_offer",
  "own_campaigns",
  "competitor_1"
)

ggpairs(data, columns = cor_cols) +
  theme_ipsum()
```

Competitor 1 seems to run campaigns when our brand has a good price offer, therefore conflating our model. We'll exclude this competitor.

```{r linear-reg2, echo=False}
predictors <- training[, c(
  "price_offer",
  "own_campaigns",
  "competitor_2",
  "competitor_3",
  "competitor_4",
  "competitor_5",
  "competitor_6", 
  "competitor_7",  
  "temperature",
  "holiday"
)]

response <- training$pizza

# Define the model and training control
linear_model2 <- train(predictors, response,
                      method = "lm",
                      trControl = trainControl(method = "cv", number = 5),
                      preProcess = c("scale"),
                      na.action = na.pass)

# Print the model summary
print(summary(linear_model2))
```

We can see at the coefficients that `price_offer` and `own_campaign`are both excellent predictors of our sales. **Competitor 2** seems to be a real competitor, having a strong negative impact on our sales. **Competitor 7**, on the other hand, has a beneficial influence, possibly due to similar product or campaign designs; the rest of the competitors' campaigns as well as temperature don't really drive our sales one way or the other, and, therefore, we ditch them.

Let's assemble our **final model** and see how well it does on the **unseen 2021 data.**

```{r linear-reg-fin, echo=False}
predictors <- training[, c(
  "price_offer",
  "own_campaigns",
  "competitor_2",
  "competitor_7",  
  "holiday"
)]

response <- training$pizza

# Define the model and training control
linear_model <- train(predictors, response,
                      method = "lm",
                      trControl = trainControl(method = "cv", number = 5),
                      preProcess = c("scale"),
                      na.action = na.pass)

# Print the model summary
print(summary(linear_model))
```

Again, first-glimpse model diagnostics look promising: Normally distributed residuals and a solid adjusted R-squared indicating that our model is able to explain 78.33% of the variance in the data.

Let's test this on the unseen test set (the 2021 data). Below we see basic model performance metrics **RMS, Rsquared, and MAE.**

```{r test-model, echo=False}
test <- data %>% 
  filter(year==2021)

test_predictors <- test[, c(
  "price_offer",
  "own_campaigns",
  "competitor_2",
  "competitor_7",  
  "holiday"
)]

predictions <- predict(linear_model, test_predictors)

postResample(predictions, test$pizza)

```

We can see that we have a reasonably low prediction error, and the R-squared we get is highly comparable to the one we got for our training set, which is likely due to the cross validation approach we used. Let's plot the **predicted versus actual pizza sales for 2021.**

```{r plot-predictions, echo=False}
test %>%
  ggplot(aes(x = date, y = pizza, 
             color = "Actual Sales")) +
  ## Add pizza sales
  geom_line(aes(x = date, y = pizza),
    size=1
  )+
  ## Add predictions
  geom_line(aes(y=predictions, 
                color = "Predicted Sales"),
            size=1) +
  ## Style  
  ggtitle("Predicted versus Actual Pizza Sales on Test Set (2021)") +
  ylab("Pizza sales in pizzas") +
  theme_ipsum(
    plot_title_size = 14,
    grid = "Y"
  ) +
  scale_x_date(expand = c(0,0))+
  xlab("Year") +
  theme_ipsum(grid = TRUE) +
  scale_color_manual(name = "", 
                     values = c("Actual Sales" = "#2EC2C7", "Predicted Sales" = "#FFA17D")) +
  scale_linetype_manual(name = "", 
                        values = c("Actual Sales" = 1, "Predicted Sales" = 2))

```

We can see that our model does a very good job, though overall slightly overestimating sales.

### Task 4: Selecting predictor variables

The **final model** was `sales ~ price_offer + own_campaigns + competitor_2 + competitor_7 + holiday`. This was based on the following:

1.  All own campaigns were combined to one variable since there was no overlap in time between campaigns
2.  `competitor_1` seemed to run campaigns when our brand has good price offers, which leads to correlation of these variables, and was thus removed.
3.  The rest of the `competitor_n` campaigns were removed based on the low influence on our sales variable as indicated by their coefficients.
4.  \_Weather variables\_\_ `sun` and `precipitation` were removed since they correlated both with temperature.
5.  `temperature` was removed based on its coefficient.
6.  `holiday` had a strong negative impact, possibly indicating that some stores selling our product are closed on these days and therefore stayed in the model.
